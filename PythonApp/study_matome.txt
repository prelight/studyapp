■ニューロン数や隠れ層を増やせば予測精度が上がるものではない
・隠れ層を増やした時の問題点
	→勾配消失問題
	→過学習(オーバーフィッティング)
・問題点の対応策
	→活性化関数を変える(tanh, ReLU, Leaky ReLU)
	→ドロップアウト


■モデル学習について
①70000(7万)のデータがあるとする
②7万のうちランダムに3万のデータ(学習データ(X_train)(2万)とテストデータ(1万))を対象とする
③学習データ(2万)を訓練データ(1万6千)と検証データ(4千)に分ける
④epochsサイズ決める(例えば50)
⑤batch_sizeを決める(例えば200)
⑥n_batchesを求める(100 = 2万/200)
⑦epochsサイズ(50回)繰り返し
  X_trainはシャッフルした方がよい  
⑧n_batches(100回)繰り返し
⑨start、endを求めシャッフルしたX_trainから要素がbatch_sizeのデータ取得
  start= i * batch_size
  end = start + batch_size
⑩n_batchesの繰り返し終了
⑪検証データを用いた評価(loss, accuracy)
⑫epochsの繰り返し終了
